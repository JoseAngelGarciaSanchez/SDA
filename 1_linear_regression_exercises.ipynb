{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Exercises\n",
    "## Econometrics Part 1 - The Linear Model\n",
    "\n",
    "**Instructor:** Jose Angel Garcia Sanchez  \n",
    "**Institution:** Université Paris 1 Panthéon-Sorbonne  \n",
    "**Course:** Sorbonne Data Analytics\n",
    "\n",
    "Thank you for having followed this first course. This notebook has been created to make you more familiar with those abstract concepts seen during the course. Any feedback about the notebook is very appreciated. Now, back to the notebook. Complete each exercise by filling in the code where indicated with `# TODO:`.\n",
    "\n",
    "_Note: You are free to use any ressources from internet, this notebook is for **you** so I really encourage you to do it by yourself and not using any code generator. That said, you are obviously free to ask any question to me and to use official documentations (pandas, numpy, scipy, statsmodels)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libs Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plot style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Understanding the Simple Linear Model\n",
    "\n",
    "Consider the simple linear model: $y_i = b_0 + b_1x_i + u_i$\n",
    "\n",
    "### Part A: Generate synthetic data\n",
    "\n",
    "Generate a dataset with:\n",
    "- Sample size: N = 100\n",
    "- True parameters: $b_0 = 5$, $b_1 = 2$\n",
    "- $x_i \\sim \\text{Uniform}(0, 10)$\n",
    "- $u_i \\sim N(0, \\sigma^2)$ with $\\sigma = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1A: Generate synthetic data\n",
    "N = 100\n",
    "b0_true = 5\n",
    "b1_true = 2\n",
    "sigma = 2\n",
    "\n",
    "# TODO: Generate x values uniformly distributed between 0 and 10\n",
    "x = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Generate error terms from normal distribution with mean 0 and standard deviation sigma\n",
    "u = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Generate y values using the linear model: y = b0 + b1*x + u\n",
    "y = # YOUR CODE HERE\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x, y, alpha=0.6, label='Observed data')\n",
    "plt.plot(x, b0_true + b1_true * x, 'r-', label=f'True line: y = {b0_true} + {b1_true}x', linewidth=2)\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title('Simple Linear Model: Synthetic Data', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"True parameters: b0 = {b0_true}, b1 = {b1_true}\")\n",
    "print(f\"Sample size: N = {N}\")\n",
    "print(f\"Error variance: σ² = {sigma**2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Manual OLS Estimation\n",
    "\n",
    "Implement OLS estimation using the formulas from the course:\n",
    "\n",
    "$$\\hat{b}_1 = \\frac{\\sum(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum(x_i - \\bar{x})^2}$$\n",
    "\n",
    "$$\\hat{b}_0 = \\bar{y} - \\hat{b}_1\\bar{x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1B: Manual OLS estimation\n",
    "\n",
    "# TODO: Calculate sample means of x and y\n",
    "x_bar = # YOUR CODE HERE\n",
    "y_bar = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Calculate b1_hat using the OLS formula\n",
    "numerator = # YOUR CODE HERE\n",
    "denominator = # YOUR CODE HERE\n",
    "b1_hat = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Calculate b0_hat\n",
    "b0_hat = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Calculate fitted values: y_hat\n",
    "y_hat = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Calculate residuals: u_hat\n",
    "u_hat = # YOUR CODE HERE\n",
    "\n",
    "print(\"OLS Estimates (Manual):\")\n",
    "print(f\"b0_hat = {b0_hat:.4f} (True: {b0_true})\")\n",
    "print(f\"b1_hat = {b1_hat:.4f} (True: {b1_true})\")\n",
    "print(f\"\\nMean of residuals: {np.mean(u_hat):.6f} (should be ≈ 0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Visualize the OLS fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1C: Visualize OLS fit\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Sort for smooth line plotting\n",
    "sort_idx = np.argsort(x)\n",
    "x_sorted = x[sort_idx]\n",
    "y_hat_sorted = y_hat[sort_idx]\n",
    "\n",
    "# TODO: Create a scatter plot of observed data\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# TODO: Plot the true regression line\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# TODO: Plot the OLS fitted line\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Show residuals for first 10 points (already implemented)\n",
    "for i in range(10):\n",
    "    plt.plot([x[i], x[i]], [y[i], y_hat[i]], 'k-', alpha=0.3, linewidth=1)\n",
    "\n",
    "plt.xlabel('x', fontsize=12)\n",
    "plt.ylabel('y', fontsize=12)\n",
    "plt.title('OLS Estimation vs True Model', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D: Calculate $R^2$\n",
    "\n",
    "Calculate the coefficient of determination:\n",
    "\n",
    "$$R^2 = \\frac{\\sum(\\hat{y}_i - \\bar{y})^2}{\\sum(y_i - \\bar{y})^2} = 1 - \\frac{\\sum \\hat{u}_i^2}{\\sum(y_i - \\bar{y})^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1D: Calculate R-squared\n",
    "\n",
    "# TODO: Calculate SST (Total Sum of Squares)\n",
    "SST = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Calculate SSR (Explained Sum of Squares)\n",
    "SSR = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Calculate SSE (Residual Sum of Squares)\n",
    "SSE = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Calculate R-squared using Method 1: R2 = SSR / SST\n",
    "R2_method1 = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Calculate R-squared using Method 2: R2 = 1 - SSE / SST\n",
    "R2_method2 = # YOUR CODE HERE\n",
    "\n",
    "print(\"Analysis of Variance:\")\n",
    "print(f\"SST (Total Sum of Squares): {SST:.4f}\")\n",
    "print(f\"SSR (Explained Sum of Squares): {SSR:.4f}\")\n",
    "print(f\"SSE (Residual Sum of Squares): {SSE:.4f}\")\n",
    "print(f\"\\nVerification: SST = SSR + SSE?\")\n",
    "print(f\"{SST:.4f} = {SSR:.4f} + {SSE:.4f} = {SSR + SSE:.4f}\")\n",
    "print(f\"\\nR² (Method 1: SSR/SST): {R2_method1:.4f}\")\n",
    "print(f\"R² (Method 2: 1 - SSE/SST): {R2_method2:.4f}\")\n",
    "print(f\"\\nInterpretation: {R2_method1*100:.2f}% of the variance in y is explained by x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Gauss-Markov Assumptions\n",
    "\n",
    "Verify the Gauss-Markov assumptions for the estimated model:\n",
    "\n",
    "1. $E(u_i|X) = 0$ (Mean of residuals should be zero)\n",
    "2. Residuals and X are uncorrelated\n",
    "3. $V(X) \\neq 0$ (X has variance)\n",
    "4. Homoskedasticity: $V(u_i) = \\sigma^2$ (constant variance)\n",
    "5. No autocorrelation: $cov(u_i, u_j) = 0$ for $i \\neq j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Verify Gauss-Markov Assumptions\n",
    "\n",
    "print(\"Gauss-Markov Assumptions Verification:\\n\")\n",
    "\n",
    "# TODO: 1. Calculate mean of residuals\n",
    "mean_residuals = # YOUR CODE HERE\n",
    "print(f\"1. E(û) = {mean_residuals:.8f} (should be ≈ 0)\")\n",
    "\n",
    "# TODO: 2. Calculate correlation between residuals and X\n",
    "# Hint: use np.corrcoef()\n",
    "corr_x_u = # YOUR CODE HERE\n",
    "print(f\"2. Corr(X, û) = {corr_x_u:.8f} (should be ≈ 0)\")\n",
    "\n",
    "# TODO: 3. Calculate variance of X\n",
    "# Hint: use np.var with ddof=1 for sample variance\n",
    "var_x = # YOUR CODE HERE\n",
    "print(f\"3. V(X) = {var_x:.4f} (should be > 0)\")\n",
    "\n",
    "print(f\"\\n4. Checking homoskedasticity (constant variance of errors):\")\n",
    "print(f\"   See diagnostic plots below\")\n",
    "\n",
    "# TODO: 5. Estimate error variance: sigma_squared_hat\n",
    "sigma_squared_hat = # YOUR CODE HERE\n",
    "print(f\"\\nEstimated σ²: {sigma_squared_hat:.4f} (True: {sigma**2})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnostic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Diagnostic plots\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Residuals vs Fitted values (check homoskedasticity)\n",
    "axes[0, 0].scatter(y_hat, u_hat, alpha=0.6)\n",
    "axes[0, 0].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Fitted values', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Residuals', fontsize=11)\n",
    "axes[0, 0].set_title('Residuals vs Fitted Values\\n(Check for homoskedasticity)', fontsize=12)\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Residuals vs X\n",
    "axes[0, 1].scatter(x, u_hat, alpha=0.6)\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0, 1].set_xlabel('x', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Residuals', fontsize=11)\n",
    "axes[0, 1].set_title('Residuals vs X\\n(Should show no pattern)', fontsize=12)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Histogram of residuals (check normality)\n",
    "axes[1, 0].hist(u_hat, bins=20, edgecolor='black', alpha=0.7, density=True)\n",
    "# Overlay normal distribution\n",
    "x_norm = np.linspace(u_hat.min(), u_hat.max(), 100)\n",
    "axes[1, 0].plot(x_norm, stats.norm.pdf(x_norm, 0, np.std(u_hat)), \n",
    "                'r-', linewidth=2, label='Normal distribution')\n",
    "axes[1, 0].set_xlabel('Residuals', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Density', fontsize=11)\n",
    "axes[1, 0].set_title('Distribution of Residuals\\n(Check for normality)', fontsize=12)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Q-Q plot (check normality)\n",
    "stats.probplot(u_hat, dist=\"norm\", plot=axes[1, 1])\n",
    "axes[1, 1].set_title('Q-Q Plot\\n(Check for normality)', fontsize=12)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TODO: Write your interpretation of the diagnostic plots\n",
    "print(\"\\n=== YOUR INTERPRETATION ===\")\n",
    "print(\"Homoskedasticity: \")\n",
    "# YOUR ANSWER HERE\n",
    "print(\"\\nNormality of residuals: \")\n",
    "# YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Variance of OLS Estimators\n",
    "\n",
    "Calculate the variance of OLS estimators:\n",
    "\n",
    "$$V(\\hat{b}_1) = \\frac{\\sigma^2}{\\sum(x_i - \\bar{x})^2}$$\n",
    "\n",
    "$$V(\\hat{b}_0) = \\frac{\\sigma^2}{N} + \\bar{x}^2 V(\\hat{b}_1)$$\n",
    "\n",
    "Where $\\hat{\\sigma}^2 = \\frac{\\sum \\hat{u}_i^2}{N - 2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: Variance of OLS estimators\n",
    "\n",
    "# TODO: Calculate estimated variance of errors\n",
    "sigma_squared_hat = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Calculate variance of b1_hat using the formula above\n",
    "var_b1_hat = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Calculate variance of b0_hat using the formula above\n",
    "var_b0_hat = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Calculate standard errors (square root of variances)\n",
    "se_b1_hat = # YOUR CODE HERE\n",
    "se_b0_hat = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Calculate t-statistics: t = (estimate - true_value) / standard_error\n",
    "# For testing H0: b0 = 0 and H0: b1 = 0\n",
    "t_stat_b0 = # YOUR CODE HERE\n",
    "t_stat_b1 = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Calculate p-values (two-tailed test)\n",
    "# Hint: p-value = 2 * (1 - stats.t.cdf(abs(t_stat), degrees_of_freedom))\n",
    "# degrees_of_freedom = N - 2\n",
    "p_value_b0 = # YOUR CODE HERE\n",
    "p_value_b1 = # YOUR CODE HERE\n",
    "\n",
    "print(\"Variance and Inference for OLS Estimators:\\n\")\n",
    "print(f\"Estimated σ²: {sigma_squared_hat:.4f}\")\n",
    "print(f\"\\nParameter estimates:\")\n",
    "print(f\"b0_hat = {b0_hat:.4f}, SE = {se_b0_hat:.4f}, t = {t_stat_b0:.4f}, p-value = {p_value_b0:.4f}\")\n",
    "print(f\"b1_hat = {b1_hat:.4f}, SE = {se_b1_hat:.4f}, t = {t_stat_b1:.4f}, p-value = {p_value_b1:.4f}\")\n",
    "\n",
    "# TODO: Calculate 95% Confidence intervals\n",
    "# CI = estimate ± t_critical * standard_error\n",
    "# t_critical for 95% CI with (N-2) degrees of freedom\n",
    "t_critical = stats.t.ppf(0.975, N - 2)\n",
    "ci_b0 = # YOUR CODE HERE (tuple with lower and upper bounds)\n",
    "ci_b1 = # YOUR CODE HERE (tuple with lower and upper bounds)\n",
    "\n",
    "print(f\"\\n95% Confidence Intervals:\")\n",
    "print(f\"b0: [{ci_b0[0]:.4f}, {ci_b0[1]:.4f}] (True: {b0_true})\")\n",
    "print(f\"b1: [{ci_b1[0]:.4f}, {ci_b1[1]:.4f}] (True: {b1_true})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Model Interpretation\n",
    "\n",
    "### Part A: Log transformations\n",
    "\n",
    "Compare different functional forms:\n",
    "1. **Linear-Linear**: $y = b_0 + b_1 x$\n",
    "2. **Log-Linear** (Semi-log): $\\log(y) = b_0 + b_1 x$ → $b_1$ is the percentage change in y for 1 unit change in x\n",
    "3. **Linear-Log**: $y = b_0 + b_1 \\log(x)$\n",
    "4. **Log-Log**: $\\log(y) = b_0 + b_1 \\log(x)$ → $b_1$ is the elasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4A: Generate data for log transformations\n",
    "\n",
    "# Generate new data with multiplicative structure\n",
    "N = 100\n",
    "x_pos = np.random.uniform(1, 10, N)  # Positive x for log transformation\n",
    "u_mult = np.random.lognormal(0, 0.3, N)  # Multiplicative error\n",
    "\n",
    "# Generate y with exponential relationship\n",
    "y_exp = 5 * np.exp(0.2 * x_pos) * u_mult\n",
    "\n",
    "# TODO: Create DataFrame with the following columns:\n",
    "# 'x': x_pos\n",
    "# 'y': y_exp\n",
    "# 'log_x': natural log of x_pos\n",
    "# 'log_y': natural log of y_exp\n",
    "df = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Fit different models using statsmodels\n",
    "# Model 1: Linear-Linear (y ~ x)\n",
    "X_lin = sm.add_constant(df['x'])\n",
    "model_lin_lin = # YOUR CODE HERE (use sm.OLS and .fit())\n",
    "\n",
    "# TODO: Model 2: Log-Linear (log(y) ~ x)\n",
    "model_log_lin = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Model 3: Linear-Log (y ~ log(x))\n",
    "model_lin_log = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Model 4: Log-Log (log(y) ~ log(x))\n",
    "model_log_log = # YOUR CODE HERE\n",
    "\n",
    "# Compare R-squared values\n",
    "print(\"Model Comparison:\\n\")\n",
    "print(f\"{'Model':<20} {'R²':<10} {'b0':<10} {'b1':<10}\")\n",
    "print(\"-\" * 50)\n",
    "# TODO: Print results for each model\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Which model fits best? Why? What is the interpretation of $b_1$ in each model?\n",
    "\n",
    "**Your Answer:**\n",
    "- Best model: _____________________\n",
    "- Interpretation of b1 in log-linear model: _____________________\n",
    "- Interpretation of b1 in log-log model: _____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Multiple Linear Regression\n",
    "\n",
    "Consider the multiple linear model:\n",
    "\n",
    "$$y_i = b_0 + b_1 x_{i,1} + b_2 x_{i,2} + b_3 x_{i,3} + u_i$$\n",
    "\n",
    "Or in matrix form: $y = Xb + u$\n",
    "\n",
    "OLS estimator: $\\hat{b} = (X'X)^{-1}X'y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5: Multiple Linear Regression\n",
    "\n",
    "# Generate data with multiple predictors\n",
    "N = 200\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate correlated predictors\n",
    "mean = [0, 0, 0]\n",
    "cov = [[1, 0.3, 0.2],\n",
    "       [0.3, 1, 0.4],\n",
    "       [0.2, 0.4, 1]]\n",
    "X_data = np.random.multivariate_normal(mean, cov, N)\n",
    "\n",
    "# True coefficients\n",
    "b_true = np.array([5, 2, -3, 1.5])\n",
    "\n",
    "# Generate y\n",
    "X_matrix = np.column_stack([np.ones(N), X_data])\n",
    "u_multi = np.random.normal(0, 2, N)\n",
    "y_multi = X_matrix @ b_true + u_multi\n",
    "\n",
    "# TODO: Implement OLS using matrix algebra\n",
    "# Step 1: Calculate X'X\n",
    "XtX = # YOUR CODE HERE\n",
    "\n",
    "# Step 2: Calculate (X'X)^(-1)\n",
    "XtX_inv = # YOUR CODE HERE (use np.linalg.inv)\n",
    "\n",
    "# Step 3: Calculate X'y\n",
    "Xty = # YOUR CODE HERE\n",
    "\n",
    "# Step 4: Calculate b_hat = (X'X)^(-1) X'y\n",
    "b_hat_multi = # YOUR CODE HERE\n",
    "\n",
    "print(\"Multiple Linear Regression Results:\\n\")\n",
    "print(\"True coefficients:\")\n",
    "print(f\"b0 = {b_true[0]}, b1 = {b_true[1]}, b2 = {b_true[2]}, b3 = {b_true[3]}\")\n",
    "print(\"\\nEstimated coefficients:\")\n",
    "# TODO: Print estimated coefficients\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# TODO: Calculate fitted values and residuals\n",
    "y_hat_multi = # YOUR CODE HERE\n",
    "u_hat_multi = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Calculate R-squared\n",
    "SST_multi = # YOUR CODE HERE\n",
    "SSE_multi = # YOUR CODE HERE\n",
    "R2_multi = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Calculate adjusted R-squared\n",
    "# Adjusted R² = 1 - (N-1)/(N-k) * (1 - R²)\n",
    "k = X_matrix.shape[1]  # number of parameters\n",
    "R2_adj_multi = # YOUR CODE HERE\n",
    "\n",
    "print(f\"\\nR² = {R2_multi:.4f}\")\n",
    "print(f\"Adjusted R² = {R2_adj_multi:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Compare with statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5B: Verify with statsmodels\n",
    "\n",
    "# TODO: Fit the model using statsmodels\n",
    "model_multi = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Print the summary\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# TODO: Compare your manual estimates with statsmodels estimates\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Comparison of estimates:\")\n",
    "print(\"=\"*60)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Projection Matrices and Geometry of OLS\n",
    "\n",
    "The OLS estimator can be understood geometrically:\n",
    "\n",
    "- $P_X = X(X'X)^{-1}X'$ is the projection matrix onto the column space of X\n",
    "- $M_X = I - P_X$ projects onto the orthogonal complement\n",
    "- $\\hat{y} = P_X y$ (projection of y onto X)\n",
    "- $\\hat{u} = M_X y$ (residuals)\n",
    "\n",
    "Properties:\n",
    "- $P_X$ is idempotent: $P_X P_X = P_X$\n",
    "- $P_X$ is symmetric: $P_X' = P_X$\n",
    "- $X'\\hat{u} = 0$ (normal equations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6: Projection matrices\n",
    "\n",
    "# TODO: Calculate projection matrix P_X = X(X'X)^(-1)X'\n",
    "P_X = # YOUR CODE HERE\n",
    "\n",
    "# TODO: Calculate M_X = I - P_X\n",
    "I = np.eye(N)\n",
    "M_X = # YOUR CODE HERE\n",
    "\n",
    "# Verify properties\n",
    "print(\"Projection Matrix Properties:\\n\")\n",
    "\n",
    "# TODO: 1. Check idempotence: P_X @ P_X should equal P_X\n",
    "P_X_squared = # YOUR CODE HERE\n",
    "idempotent_check = # YOUR CODE HERE (use np.allclose)\n",
    "print(f\"1. P_X is idempotent (P_X @ P_X = P_X): {idempotent_check}\")\n",
    "\n",
    "# TODO: 2. Check symmetry: P_X should equal P_X.T\n",
    "symmetric_check = # YOUR CODE HERE\n",
    "print(f\"\\n2. P_X is symmetric (P_X = P_X'): {symmetric_check}\")\n",
    "\n",
    "# TODO: 3. Check that P_X @ y gives fitted values\n",
    "y_hat_projection = # YOUR CODE HERE\n",
    "projection_check = # YOUR CODE HERE\n",
    "print(f\"\\n3. ŷ = P_X y: {projection_check}\")\n",
    "\n",
    "# TODO: 4. Check that M_X @ y gives residuals\n",
    "u_hat_projection = # YOUR CODE HERE\n",
    "residual_check = # YOUR CODE HERE\n",
    "print(f\"\\n4. û = M_X y: {residual_check}\")\n",
    "\n",
    "# TODO: 5. Check normal equations: X' @ u_hat should be approximately 0\n",
    "normal_eq = # YOUR CODE HERE\n",
    "normal_check = # YOUR CODE HERE\n",
    "print(f\"\\n5. Normal equations (X'û = 0): {normal_check}\")\n",
    "print(f\"   Max absolute value: {np.max(np.abs(normal_eq)):.10f}\")\n",
    "\n",
    "# TODO: 6. Check orthogonality: y_hat'u_hat should be approximately 0\n",
    "orthogonality = # YOUR CODE HERE\n",
    "ortho_check = # YOUR CODE HERE\n",
    "print(f\"\\n6. ŷ ⊥ û (orthogonality): {ortho_check}\")\n",
    "print(f\"   ŷ'û = {orthogonality:.10f}\")\n",
    "\n",
    "# TODO: 7. Verify Pythagorean theorem: ||y - y_bar||² = ||ŷ - y_bar||² + ||û||²\n",
    "y_norm_sq = # YOUR CODE HERE\n",
    "y_hat_norm_sq = # YOUR CODE HERE\n",
    "u_hat_norm_sq = # YOUR CODE HERE\n",
    "pythagoras_check = # YOUR CODE HERE\n",
    "print(f\"\\n7. Pythagorean theorem (SST = SSR + SSE): {pythagoras_check}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7: Simulation Study - Consistency and Asymptotic Properties\n",
    "\n",
    "Investigate the asymptotic properties of OLS estimators by simulation:\n",
    "- Show that estimates converge to true values as N increases (consistency)\n",
    "- Show that the variance decreases as N increases\n",
    "- Verify asymptotic normality using the Central Limit Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 7: Consistency simulation\n",
    "\n",
    "# True parameters\n",
    "b0_true_sim = 3\n",
    "b1_true_sim = 1.5\n",
    "sigma_sim = 2\n",
    "\n",
    "# Different sample sizes\n",
    "sample_sizes = [20, 50, 100, 200, 500, 1000, 2000, 5000]\n",
    "n_simulations = 1000\n",
    "\n",
    "results = {}\n",
    "\n",
    "# TODO: For each sample size, run n_simulations replications\n",
    "for N_sim in sample_sizes:\n",
    "    b0_estimates = []\n",
    "    b1_estimates = []\n",
    "    \n",
    "    for _ in range(n_simulations):\n",
    "        # TODO: Generate data\n",
    "        x_sim = # YOUR CODE HERE\n",
    "        u_sim = # YOUR CODE HERE\n",
    "        y_sim = # YOUR CODE HERE\n",
    "        \n",
    "        # TODO: Estimate parameters using OLS formulas\n",
    "        x_bar_sim = # YOUR CODE HERE\n",
    "        y_bar_sim = # YOUR CODE HERE\n",
    "        b1_hat_sim = # YOUR CODE HERE\n",
    "        b0_hat_sim = # YOUR CODE HERE\n",
    "        \n",
    "        b0_estimates.append(b0_hat_sim)\n",
    "        b1_estimates.append(b1_hat_sim)\n",
    "    \n",
    "    # TODO: Store results (mean and variance of estimates)\n",
    "    results[N_sim] = {\n",
    "        'b0_mean': # YOUR CODE HERE,\n",
    "        'b0_var': # YOUR CODE HERE,\n",
    "        'b1_mean': # YOUR CODE HERE,\n",
    "        'b1_var': # YOUR CODE HERE,\n",
    "        'b0_estimates': b0_estimates,\n",
    "        'b1_estimates': b1_estimates\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "print(f\"Consistency Simulation ({n_simulations} replications per sample size)\\n\")\n",
    "print(f\"True parameters: b0 = {b0_true_sim}, b1 = {b1_true_sim}\\n\")\n",
    "print(f\"{'N':<8} {'E(b0_hat)':<12} {'V(b0_hat)':<12} {'E(b1_hat)':<12} {'V(b1_hat)':<12}\")\n",
    "print(\"-\" * 60)\n",
    "for N_sim in sample_sizes:\n",
    "    r = results[N_sim]\n",
    "    print(f\"{N_sim:<8} {r['b0_mean']:<12.4f} {r['b0_var']:<12.6f} {r['b1_mean']:<12.4f} {r['b1_var']:<12.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 7: Visualize consistency\n",
    "\n",
    "# TODO: Create plots showing:\n",
    "# 1. Mean of b0_hat vs sample size\n",
    "# 2. Mean of b1_hat vs sample size\n",
    "# 3. Variance of b0_hat vs sample size (log scale)\n",
    "# 4. Variance of b1_hat vs sample size (log scale)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What do you observe about the behavior of the estimators as sample size increases?\n",
    "\n",
    "**Your Answer:**\n",
    "- Consistency: _____________________\n",
    "- Variance behavior: _____________________\n",
    "- Practical implication: _____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8: Real Data Application\n",
    "\n",
    "Apply the concepts to a realistic wage dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 8: Create a realistic dataset\n",
    "\n",
    "np.random.seed(123)\n",
    "n_obs = 500\n",
    "\n",
    "# Generate realistic variables\n",
    "education = np.random.normal(13, 2.5, n_obs)\n",
    "education = np.clip(education, 8, 20)\n",
    "\n",
    "experience = np.random.gamma(5, 2, n_obs)\n",
    "experience = np.clip(experience, 0, 40)\n",
    "\n",
    "age = 18 + education + experience + np.random.normal(0, 1, n_obs)\n",
    "age = np.clip(age, 22, 65)\n",
    "\n",
    "female = np.random.binomial(1, 0.48, n_obs)\n",
    "\n",
    "# Generate wage\n",
    "log_wage = (1.5 + \n",
    "           0.08 * education + \n",
    "           0.03 * experience + \n",
    "           -0.0005 * experience**2 + \n",
    "           -0.15 * female + \n",
    "           np.random.normal(0, 0.3, n_obs))\n",
    "\n",
    "wage = np.exp(log_wage)\n",
    "\n",
    "# TODO: Create DataFrame\n",
    "df_wage = pd.DataFrame({\n",
    "    # YOUR CODE HERE\n",
    "})\n",
    "\n",
    "# TODO: Display summary statistics\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 8: Exploratory data analysis\n",
    "\n",
    "# TODO: Create the following plots:\n",
    "# 1. Wage vs Education\n",
    "# 2. Log(Wage) vs Education\n",
    "# 3. Wage vs Experience\n",
    "# 4. Wage distribution by gender\n",
    "# 5. Education distribution\n",
    "# 6. Correlation heatmap\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 8: Estimate wage equations\n",
    "\n",
    "# TODO: Estimate the following models:\n",
    "# Model 1: log(wage) ~ education\n",
    "# Model 2: log(wage) ~ education + experience\n",
    "# Model 3: log(wage) ~ education + experience + experience²\n",
    "# Model 4: log(wage) ~ education + experience + experience² + female\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# TODO: Compare models using R² and adjusted R²\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# TODO: Print summary of the final model\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 8: Interpretation\n",
    "\n",
    "# TODO: Answer the following questions based on your final model:\n",
    "\n",
    "print(\"Economic Interpretation:\\n\")\n",
    "print(\"1. Returns to Education:\")\n",
    "print(\"   Coefficient: _____\")\n",
    "print(\"   Interpretation: One additional year of education increases wages by _____%\")\n",
    "print()\n",
    "\n",
    "print(\"2. Returns to Experience:\")\n",
    "print(\"   What is the marginal effect of experience at 10 years? _____\")\n",
    "print(\"   What is the marginal effect of experience at 25 years? _____\")\n",
    "print(\"   At what level of experience do returns peak? _____\")\n",
    "print()\n",
    "\n",
    "print(\"3. Gender Wage Gap:\")\n",
    "print(\"   Coefficient: _____\")\n",
    "print(\"   Interpretation: _____\")\n",
    "print()\n",
    "\n",
    "print(\"4. Model Fit:\")\n",
    "print(\"   R²: _____\")\n",
    "print(\"   Interpretation: _____\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 9: Challenge Questions\n",
    "\n",
    "Test your understanding with these questions:\n",
    "\n",
    "### Question 1\n",
    "What happens to $R^2$ when you add an irrelevant variable to the model? Why should we use adjusted $R^2$ instead? Demonstrate with code.\n",
    "\n",
    "**Your Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: Demonstrate the effect of adding an irrelevant variable\n",
    "\n",
    "# TODO: Add a random noise variable to the wage dataset\n",
    "# TODO: Estimate two models (with and without the noise variable)\n",
    "# TODO: Compare R² and adjusted R²\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Explain the difference between the error term $u_i$ and the residual $\\hat{u}_i$.\n",
    "\n",
    "**Your Answer:**\n",
    "\n",
    "\n",
    "### Question 3\n",
    "Why is correlation not causality? Give an example from economics.\n",
    "\n",
    "**Your Answer:**\n",
    "\n",
    "\n",
    "### Question 4\n",
    "What is the interpretation of a coefficient in a log-log model vs a log-linear model?\n",
    "\n",
    "**Your Answer:**\n",
    "- Log-log: \n",
    "- Log-linear:\n",
    "\n",
    "### Question 5\n",
    "Verify mathematically and computationally that the regression line always passes through the point $(\\bar{x}, \\bar{y})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5: Verify regression line passes through (x̄, ȳ)\n",
    "\n",
    "# TODO: Use your estimates from Exercise 1\n",
    "# TODO: Calculate ŷ(x̄) and compare with ȳ\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(\"Mathematical proof:\")\n",
    "print(\"We know that b0_hat = ȳ - b1_hat * x̄\")\n",
    "print(\"Therefore: ŷ(x̄) = b0_hat + b1_hat * x̄\")\n",
    "print(\"         = (ȳ - b1_hat * x̄) + b1_hat * x̄\")\n",
    "print(\"         = ȳ\")\n",
    "print(\"QED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### Main Concepts Covered:\n",
    "\n",
    "1. **Simple Linear Model**: $y_i = b_0 + b_1 x_i + u_i$\n",
    "   - Error term vs residuals\n",
    "   - OLS estimation formulas\n",
    "   - Interpretation of coefficients\n",
    "\n",
    "2. **Gauss-Markov Assumptions**:\n",
    "   - $E(u_i|X) = 0$\n",
    "   - $X$ and $u$ uncorrelated\n",
    "   - $V(X) \\neq 0$\n",
    "   - Homoskedasticity: $V(u_i) = \\sigma^2$\n",
    "   - No autocorrelation\n",
    "\n",
    "3. **Properties of OLS Estimators**:\n",
    "   - BLUE (Best Linear Unbiased Estimators)\n",
    "   - Consistency (convergence in probability)\n",
    "   - Asymptotic normality (via CLT)\n",
    "\n",
    "4. **Goodness of Fit**:\n",
    "   - $R^2$: proportion of variance explained\n",
    "   - Adjusted $R^2$: penalty for additional variables\n",
    "   - Analysis of variance: SST = SSR + SSE\n",
    "\n",
    "5. **Multiple Linear Regression**:\n",
    "   - Matrix formulation: $y = Xb + u$\n",
    "   - OLS estimator: $\\hat{b} = (X'X)^{-1}X'y$\n",
    "   - Projection matrices and geometry of OLS\n",
    "\n",
    "6. **Model Specification**:\n",
    "   - Log transformations for different interpretations\n",
    "   - Polynomial terms for nonlinear relationships\n",
    "   - Dummy variables for categorical variables\n",
    "\n",
    "### Reflection Questions:\n",
    "\n",
    "1. What was the most challenging concept in this notebook?\n",
    "2. How does the geometric interpretation of OLS help your understanding?\n",
    "3. When would you use log transformations in practice?\n",
    "4. What assumptions are most likely to be violated in real-world applications?\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Practice with real datasets\n",
    "- Learn about hypothesis testing in regression\n",
    "- Study violations of Gauss-Markov assumptions (heteroskedasticity, autocorrelation)\n",
    "- Explore advanced topics: instrumental variables, panel data, time series"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
