{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y0nBlEslq5o"
      },
      "source": [
        "# Lab 1 Tutorial: Deep Learning with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hide_input": false,
        "id": "UAeGdODJlq5o"
      },
      "outputs": [],
      "source": [
        "# Auto-setup when running on Google Colab\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    !pip install openml\n",
        "\n",
        "# General imports\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZYkUBmQlq5o"
      },
      "source": [
        "## Torch tensors\n",
        "Whereas we have been using numpy arrays and pandas dataframes for most of the course, PyTorch (we'll often say Torch for simplicity) uses tensors to encode the inputs and outputs of a model, as well as the model's parameters.\n",
        "\n",
        "Tensors are multi-dimensional arrays, and very similar to NumPy's ndarrays, except that tensors can run on GPUs or other specialized hardware to accelerate computing. Tensors are stored on a `device`, like a cpu or gpu.\n",
        "\n",
        "### Initialization\n",
        "You can create tensors from existing lists, arrays, or a range of existing initializers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eJRBpkElq5p"
      },
      "outputs": [],
      "source": [
        "# List to Tensor\n",
        "data = [[1, 2], [3, 4]]\n",
        "x_data = torch.tensor(data)\n",
        "\n",
        "# Initialize with a given shape\n",
        "shape = (2, 3, )\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "\n",
        "print(f\"From list Tensor: \\n {x_data} \\n\")\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM0cP5GYlq5p"
      },
      "source": [
        "You can move between Numpy arrays and tensors in both directions.\n",
        "Careful: if your tensor is stored on cpu, it will point to the same object in memory as the Numpy array, and changing one will change the other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqcNqj5Slq5q"
      },
      "outputs": [],
      "source": [
        "# Numpy to Tensor\n",
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)\n",
        "print(f\"Tensor original: \\n {x_np} \\n\")\n",
        "\n",
        "# Tensor to Numpy\n",
        "np_array = x_np.numpy()\n",
        "\n",
        "# Change the tensor\n",
        "x_np.add_(1) # The underscore _ means that the operation is done in place\n",
        "print(f\"Tensor changed: \\n {x_np} \\n\")\n",
        "print(f\"Numpy array has also changed: \\n {np_array} \\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSd7IP9glq5q"
      },
      "source": [
        "### Attributes\n",
        "You can query a tensor's shape, datatype, and device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmW5xOTYlq5q"
      },
      "outputs": [],
      "source": [
        "tensor = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hctckWCBlq5r"
      },
      "source": [
        "### Switching to GPU\n",
        "You can move the tensor to the GPU using the .to method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHhDODljlq5r"
      },
      "outputs": [],
      "source": [
        "# We move our tensor to the GPU if available\n",
        "# For CUDA-based systems\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to('cuda')\n",
        "  device = torch.device('cuda:0')\n",
        "  print(f\"Device tensor is stored on: {tensor.device}\")\n",
        "\n",
        "# For Mac M1/M4-based systems\n",
        "if torch.backends.mps.is_available():\n",
        "  device = torch.device(\"mps\")\n",
        "  tensor = tensor.to(device)\n",
        "\n",
        "print(f\"Tensor is stored on device: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glDk6-65lq5r"
      },
      "source": [
        "<div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>NOTE:</strong></div>\n",
        "If your laptop has a GPU, we strongly recommend that you figure out how to use it.\n",
        "\n",
        "For **Windows** machines, you probably need to <a href=\"https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/\">install CUDA</a>.\n",
        "\n",
        "For **Macs** with M1/M4 chips, it should work out of the box.</p>\n",
        "\n",
        "If you're using **Colab**, allocate a GPU by going to Edit \\> Notebook Settings.\n",
        "At the time of writing, T4 GPUs are free to use, and fine for doing the labs. Better GPUs like the A100 will consume credits. On the top right, click the down arrow and then 'View resources'.\n",
        "\n",
        "For large-scale experiments, see the guide on using the **Snellius Supercomputer** using your course credits.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFLoZGZHlq5r"
      },
      "source": [
        "### Tensor operations\n",
        "There are over 100 tensor operations, including transposing, indexing, slicing,\n",
        "mathematical operations, linear algebra, and random sampling. Since you are already familiar with the Numpy API, you'll find these very familiar. See\n",
        "[here](https://pytorch.org/docs/stable/torch.html) for a full list of tensor operations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-5giHa_lq5s"
      },
      "outputs": [],
      "source": [
        "# Indexing and slicing\n",
        "tensor = torch.ones(4, 4)\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZ0rvnWIlq5s"
      },
      "outputs": [],
      "source": [
        "# Joining\n",
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEYPfxo6lq5s"
      },
      "outputs": [],
      "source": [
        "# Matrix multiplication (matmul)\n",
        "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
        "# Alternative syntax:\n",
        "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjTMa80clq5s"
      },
      "source": [
        "## Neural Network training (backpropagation)\n",
        "As a reminder, training a neural network (NN) is a series of functions (e.g. matrix multiplications, activation functions, softmax operations), many of which have parameters (model weights and biases) that define the exact output. Training\n",
        "typically occurs in two steps:\n",
        "\n",
        "**Forward Propagation**: The NN runs the input data through each of its\n",
        "functions to make its best guess about the correct output. After this, we compute the error (loss).\n",
        "\n",
        "**Backward Propagation**: In backprop, the NN adjusts its parameters\n",
        "proportionate to the error in its guess. It does this by traversing\n",
        "backwards from the output, collecting the derivatives of the error with\n",
        "respect to the parameters of the functions (*gradients*), and optimizing\n",
        "the parameters using gradient descent. For a more detailed walkthrough\n",
        "of backprop, check out [this](https://www.youtube.com/watch?v=Ilg3gGewQ5U&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) and [this](https://www.youtube.com/watch?v=tIeHLnjs5U8) video from 3Blue1Brown.\n",
        "\n",
        "To illustrate how this works, we'll start from a pretrained resnet18 model. We create a random 64x64 input image and feed it to the network.\n",
        "Note: this example only works on CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4ctRoUglq5s"
      },
      "outputs": [],
      "source": [
        "# Import a pretrained model and its weights\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "\n",
        "# Create a random input. The model expects a 4D tensor.\n",
        "# The first dimension is the batch size (1), the second is the number of channels (red-green-blue),\n",
        "# and the last two are the height and width of the input.\n",
        "data = torch.rand(1, 3, 64, 64)\n",
        "labels = torch.rand(1, 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr9kJbE5lq5t"
      },
      "source": [
        "**Forward pass**: simply feed the input to the model to get its predictions.\n",
        "Then, based on the predictions, we can compute the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gl63s7s5lq5u"
      },
      "outputs": [],
      "source": [
        "prediction = model(data) # forward pass\n",
        "\n",
        "loss_fn = torch.nn.MSELoss() # Mean Squared Error loss (we'll discuss torch.nn in more detail later)\n",
        "loss = loss_fn(prediction, labels) # this returns a Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl4E0zXzlq5u"
      },
      "source": [
        "**Backward pass**  \n",
        "Step 1: Compute the gradients by calling `.backward()`. PyTorch’s _autograd_ engine will calculate and store the gradients for each model parameter (in the parameter’s `.grad` attribute).\n",
        "\n",
        "There is a lot going on in the background. In short, every time you perform a forward pass, PyTorch dynamically constructs a _computational graph_ that tracks tensors and operations involved in computing gradients. When you call `.backward()`, PyTorch traverses this graph in reverse to compute all gradients efficiently using a process called _automatic differentiation_. To optimize computation, PyTorch stores intermediate values needed for gradient calculation while applying the chain rule. Once `backward()` completes, the computational graph is discarded to free memory, unless `retain_graph=True` is specified. This means you can modify the model’s structure (e.g., shape, size, and operations) at every iteration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugZv5ywolq5u"
      },
      "outputs": [],
      "source": [
        "loss.backward() # backward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REG6PVz6lq5u"
      },
      "source": [
        "It's important to understand that `loss` is a Tensor, and in PyTorch, every tensor that results from an operation is also a node in the computational graph (at least if it has the property `requires_grad=True`). Hence, `loss` is the last node in the computational graph, and by calling `backward`, PyTorch will traverse the graph backwards and attach all the gradients to all the (learnable) tensors it encounters. We will visualize the computational graph below (ResNet has a huge graph)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVNQvI0nlq5u"
      },
      "outputs": [],
      "source": [
        "loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_01CAHAalq5u"
      },
      "source": [
        "Step 2: Choose an optimizer (e.g. stochastic gradient descent) and its hyperparameters (e.g. learning rate). Then do one `.step()` with the optimizer to update the model weigths.\n",
        "\n",
        "The expression model.parameters() in PyTorch returns an iterator over all learnable parameters (weights and biases) of the model (i.e., tensors with requires_grad=True). When we ran `backward()` we added the gradients to the parameters, and the optimizer will use these gradients to update the parameters when we run `step`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Usu-zxh_lq5u"
      },
      "outputs": [],
      "source": [
        "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
        "optim.step() #gradient descent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5eMoqDjlq5u"
      },
      "source": [
        "**Recap.** One training cycle thus consists of these simple commands, and now you also understand how they work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTcdnxH8lq5u"
      },
      "outputs": [],
      "source": [
        "prediction = model(data) # forward pass\n",
        "loss = loss_fn(prediction, labels) # compute loss\n",
        "loss.backward() # backward pass (compute all gradients)\n",
        "optim.step() # update model weigths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYunRKKglq5u"
      },
      "source": [
        "## Building Neural Networks\n",
        "It's now time to build a complete NN. This can be done via the `torch.nn` package, which contains a lot of components (e.g. layers such as `nn.Conv2d`) and the `torch.nn.functional` module which contains functions such as `relu` and `max_pool`.\n",
        "\n",
        "Defining a NN works buy defining a Python class:\n",
        "* Create a subclass of `nn.Module`.\n",
        "* In the `__init__` method, define the components that you will use and their hyperparameters.\n",
        "* In the `forward` method, define the structure of the network. Pass the input to the required functions and layers, store the result in a variable, and pass it to the next function.\n",
        "\n",
        "For example, let's implement the convolutional network (LeNet) in the image below\n",
        "![convnet](https://pytorch.org/tutorials/_static/img/mnist.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "an02sGXtlq5u"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels (filters), 5x5 square convolution kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        # 6 input channels, 16 output channels (filters), 5x5 square convolution kernel\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # Fully connected layers.\n",
        "        # After flattening the conv2 output, we get a vector of 16 * 5 * 5\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # 120 hidden nodes\n",
        "        self.fc2 = nn.Linear(120, 84) # 84 hidden nodes\n",
        "        self.fc3 = nn.Linear(84, 10) # 10 output nodes (classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Convolution layer: conv1 + RELU activation function\n",
        "        # Outputs a Tensor with size (N, 6, 28, 28), where N is the size of the batch\n",
        "        c1 = F.relu(self.conv1(input))\n",
        "        # Maxpooling (subsampling)) layer: 2x2 grid\n",
        "        # This layer does not have any parameters, outputs a (N, 6, 14, 14) Tensor\n",
        "        s2 = F.max_pool2d(c1, (2, 2))\n",
        "        # Convolution layer: conv2 + RELU activation\n",
        "        # Outputs a (N, 16, 10, 10) Tensor\n",
        "        c3 = F.relu(self.conv2(s2))\n",
        "        # Maxpooling layer S4: 2x2 grid\n",
        "        # Outputs a (N, 16, 5, 5) Tensor\n",
        "        s4 = F.max_pool2d(c3, 2)\n",
        "        # Flatten operation: outputs a (N, 400) Tensor (16*5*5)\n",
        "        s4 = torch.flatten(s4, 1)\n",
        "        # Fully connected layer + RELU activation\n",
        "        # (N, 400) Tensor input, outputs a (N, 120) Tensor\n",
        "        f5 = F.relu(self.fc1(s4))\n",
        "        # Fully connected layer + RELU activation\n",
        "        # (N, 120) Tensor input, outputs a (N, 84) Tensor\n",
        "        f6 = F.relu(self.fc2(f5))\n",
        "        # Output layer:\n",
        "        # (N, 84) Tensor input, outputs a (N, 10) Tensor\n",
        "        output = self.fc3(f6)\n",
        "        return output\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBiCzxdElq5u"
      },
      "source": [
        "Inspect the number of learnable parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2rBEpy6lq5u"
      },
      "outputs": [],
      "source": [
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total learnable parameters: {num_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLcQSXTplq5u"
      },
      "source": [
        "Toy training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyKLsLLllq5u"
      },
      "outputs": [],
      "source": [
        "input = torch.randn(1, 1, 32, 32) # random input image\n",
        "target = torch.randn(10)  # a dummy target\n",
        "target = target.view(1, -1)  # make it the same shape as output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvFMA5TOlq5u"
      },
      "source": [
        "**Forward pass**: Passing input through the network calls the `forward` method of the model, computing and returning the output of the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCBXXz-1lq5v"
      },
      "outputs": [],
      "source": [
        "out = net(input)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLisVd4-lq5v"
      },
      "source": [
        "**Compute loss**: same as before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6J8WxAlflq5v"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.MSELoss() # Mean Squared Error loss\n",
        "loss = loss_fn(out, target)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSzqbNlclq5v"
      },
      "source": [
        "You can run the code below to visualize the computational graph ending in `loss` (green box). It will show all the operations and the learnable model parameters in blue boxes (biases and weights in separate boxes)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz"
      ],
      "metadata": {
        "id": "VBxzUyGAmGqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFer1XZ_lq5v"
      },
      "outputs": [],
      "source": [
        "from torchviz import make_dot\n",
        "graph = make_dot(loss, params=dict(model.named_parameters()))\n",
        "graph.render(\"computational_graph\", format=\"png\", view=True)\n",
        "\n",
        "# Display inside Jupyter Notebook\n",
        "from IPython.display import Image\n",
        "Image(\"computational_graph.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqs-0ZG4lq5v"
      },
      "source": [
        "**Backward pass**. In PyTorch, you need to zero the gradients of all parameters before performing a new backward pass because gradients accumulate by default. This behavior is designed to support techniques like mini-batch gradient accumulation, but in standard training loops, failing to zero out the gradients can lead to incorrect updates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grU9ydOIlq5w"
      },
      "outputs": [],
      "source": [
        "net.zero_grad() # zeroes the gradient buffers of all parameters\n",
        "\n",
        "print('Gradients of Conv1 biases, after zero_grad, before backward:', net.conv1.bias.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('Gradients of Conv1 biases, after backward:', net.conv1.bias.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8UF6uEqlq5w"
      },
      "source": [
        "**Optimizer step**: Create an SGD optimizer on the model parameters and do a step. Notice that the parameters have changed slightly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6DxlM4Tlq5w"
      },
      "outputs": [],
      "source": [
        "optim = torch.optim.SGD(net.parameters(), lr=1e-2, momentum=0.9)\n",
        "\n",
        "print('Weights of Conv1 biases, before step:', net.conv1.bias)\n",
        "optim.step() #gradient descent\n",
        "print('Weights of Conv1 biases, after step:', net.conv1.bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24YEHRR9lq5w"
      },
      "source": [
        "## Training a classifier for CIFAR-10\n",
        "\n",
        "We'll now do a complete training run on the CIFAR10 dataset. It has the classes:\n",
        "'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse',\n",
        "'ship', 'truck'. The images in CIFAR-10 are of size 3x32x32, i.e.\n",
        "3-channel color images of 32x32 pixels in size.\n",
        "\n",
        "![cifar10](https://pytorch.org/tutorials/_static/img/cifar10.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Efg8IrAKlq5w"
      },
      "source": [
        "### Loading the data\n",
        "We can het the CIFAR10 datasets from `torchvision`, but since these are PILImage images, we'll need to transform them to Tensors first and normalize them. We'll also create a separate training and test set (using a predefined split). We'll also create data loaders that will return batches of 4 images at a time.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sV0SwWT3lq5w"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ktX-iavlq5w"
      },
      "source": [
        "Let's peek at some of the images returned by our dataloader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2BbkEkflq5w"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Function to show a batch of images with labels underneath\n",
        "def show_images(images, labels, classes):\n",
        "    images = images / 2 + 0.5\n",
        "    np_images = images.numpy()\n",
        "\n",
        "    batch_size = len(images)\n",
        "    fig, axes = plt.subplots(1, batch_size, figsize=(batch_size * 2, 2))\n",
        "\n",
        "    if batch_size == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for idx, ax in enumerate(axes):\n",
        "        ax.imshow(np.transpose(np_images[idx], (1, 2, 0)))  # Convert (C, H, W) to (H, W, C)\n",
        "        ax.set_title(classes[labels[idx]], fontsize=10)  # Set label as title\n",
        "        ax.axis(\"off\")  # Hide axes\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Show images with class labels above\n",
        "show_images(images, labels, classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdkgfG5Vlq5w"
      },
      "source": [
        "### Create the neural network\n",
        "We will re-create the network we had before, but now using 3-channel inputs since these are colored images. We'll also condense the code, as is often done. Check that it is still the same network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kKrQJV9lq5x"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCpXilhllq5x"
      },
      "source": [
        "Sidenote: simple networks like this, which are a pure sequence of layers, can also be defined by the Sequential API, which is much simpler:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSxTeXCOlq5x"
      },
      "outputs": [],
      "source": [
        "net_sequential = nn.Sequential(\n",
        "    nn.Conv2d(3, 6, 5),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "\n",
        "    nn.Conv2d(6, 16, 5),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2, 2),\n",
        "\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(16 * 5 * 5, 120),\n",
        "    nn.ReLU(),\n",
        "\n",
        "    nn.Linear(120, 84),\n",
        "    nn.ReLU(),\n",
        "\n",
        "    nn.Linear(84, 10)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJtswroHlq5x"
      },
      "source": [
        "Put the network on GPU if possible. Note that when we train the network, we also need to put the data on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4Z4GILelq5x"
      },
      "outputs": [],
      "source": [
        "net.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvsdRI4Ylq5x"
      },
      "source": [
        "We'll use cross-entropy loss and an SGD optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCwvVlaHlq5x"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCjM2T-mlq5x"
      },
      "source": [
        "### Train the network\n",
        "To train the network, we have to do all the steps we discussed before in a loop. Each iteration, we'll get a new batch of data from the dataloader, and we'll also repeat this for 2 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDeNQykplq5x"
      },
      "outputs": [],
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        # Put the data on GPU if possible\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjJ0B-jYlq5x"
      },
      "source": [
        "### Test the network\n",
        "Let's see whether the model makes good predictions. We'll take some examples from out test set loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37xTn9cIlq5y"
      },
      "outputs": [],
      "source": [
        "# Get a batch of test images\n",
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "show_images(images, labels, classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30nyYS6glq5y"
      },
      "source": [
        "Get the outputs from the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o35iuNlylq5y"
      },
      "outputs": [],
      "source": [
        "outputs = net(images.to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4bU47vnlq5y"
      },
      "source": [
        "Since the model returns probabilities, we'll take the class with the highest probability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUNKiXRQlq5y"
      },
      "outputs": [],
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
        "                              for j in range(4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vWQcdPDlq5y"
      },
      "source": [
        "Now, let's evaluate on the whole test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ9dBtpwlq5y"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(inputs)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrF2KEZJlq5y"
      },
      "source": [
        "### Saving and reloading\n",
        "Finally, let's see how we can save the model to disk and load it again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RauO1yFlq5y"
      },
      "outputs": [],
      "source": [
        "# Saving the trained model\n",
        "torch.save(net.state_dict(), './cifar_net.pth')\n",
        "\n",
        "# Load the trained model\n",
        "net = Net()\n",
        "net.load_state_dict(torch.load('./cifar_net.pth', weights_only=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98T1jhbJlq5y"
      },
      "source": [
        "## Pytorch Lightning\n",
        "We did have to write quite a bit of code to build and train the model.\n",
        "[PyTorch Lightning](https://www.pytorchlightning.ai/) is a handy library that abstracts away boilerplate code and provides a fit() function similar to sklearn or Keras.\n",
        "\n",
        "See the code below for an example. Here we used a resnet, but you can also use your own network."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning"
      ],
      "metadata": {
        "id": "xRhARcaZm5GV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrLJXooIlq5y"
      },
      "outputs": [],
      "source": [
        "import lightning as L\n",
        "\n",
        "# Define the LightningModule\n",
        "class LitModel(L.LightningModule):\n",
        "    def __init__(self, model, criterion):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.training_loss_history = []  # Store loss values\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        inputs, labels = batch\n",
        "        outputs = self.model(inputs)\n",
        "        loss = self.criterion(outputs, labels)\n",
        "\n",
        "        # Log loss for visualization\n",
        "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True, on_step=True)\n",
        "\n",
        "        # Store loss in history (needed for manual plotting)\n",
        "        self.training_loss_history.append(loss.item())\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.SGD(self.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# Load dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Define model\n",
        "net = torchvision.models.resnet18(num_classes=10)  # Example model\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Wrap the model in Lightning\n",
        "lit_model = LitModel(net, criterion)\n",
        "\n",
        "# Train using PyTorch Lightning Trainer\n",
        "trainer = L.Trainer(max_epochs=2)\n",
        "trainer.fit(lit_model, trainloader)\n",
        "\n",
        "# Plot loss curve\n",
        "plt.plot(lit_model.training_loss_history, label=\"Training Loss\", linestyle=\"-\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss Curve\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h86PItKlq5z"
      },
      "source": [
        "## Tensorboard\n",
        "TensorBoard is a visualization toolkit for tracking and analyzing deep learning experiments. It can log:\n",
        "* Training loss curves\n",
        "* Validation accuracy over epochs\n",
        "* Model graphs\n",
        "* Histograms of weights & gradients\n",
        "* Images, embeddings, and more\n",
        "\n",
        "We can log our model training as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEC7koUvlq5z"
      },
      "outputs": [],
      "source": [
        "import lightning.pytorch as pl\n",
        "logger = pl.loggers.TensorBoardLogger(\"logs/\", name=\"my_experiment\")\n",
        "trainer = pl.Trainer(max_epochs=2, logger=logger)\n",
        "trainer.fit(lit_model, trainloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgKji5gQlq5z"
      },
      "source": [
        "Normally, you would open tensorboard from the command line with\n",
        "```\n",
        "tensorboard --logdir logs\n",
        "```\n",
        "\n",
        "But we can also integrate it here using some magic:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkRzFBvLlq5z"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS8Lam3Mlq5z"
      },
      "source": [
        "TODO:\n",
        "* More on drawing learning curves\n",
        "* Regularization (Early stopping, L1/L2, Dropout, Batchnorm)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "celltoolbar": "Slideshow",
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}